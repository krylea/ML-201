# Machine Learning 201: Tips and Tricks
I have been spending the past year on what has effectively been an ongoing machine learning crash course. I started last september with an extremely minimal knowledge of machine learning, and was immediately thrust into a number of projects involving Natural Language Processing (or NLP) models making use of complicated Recurrent Neural Network architectures. At the time, this felt overwhelming and extremely stressful, but as I look back I realize it was a blessing in disguise. What I have found is that many of the existing resources for learning how to actually *do* machine learning - e.g. classes, blog posts, MOOCs - share a number of common failures. In my experience, the best - in fact, the *only* - place to really learn a lot of the critical information you need to know in order to really know how to really make deep learning models work to their full potential is other people who are already doing it. There are just so many things that I've needed to know that I have never found on a blog post or in course lecture notes - which recurrent architectures work best, how to properly implement masking, heuristics for designing network architectures, how to choose good hyperparameters, etc...

I have also found that all existing resources tend to fall into one of two categories. On the one hand there are a plethora of well-intentioned blog posts written by hobbyists, students, professionals, etc... aimed to teach the absolute basics of what machine learning *is* and the high-level intuition behind deep learning models. These resources are great for getting a high-level overview of how certain models work and what the intuition behind their design is. They tell you almost nothing, however, about how to actually *do* it - and when they try they often get things wrong, sometimes *very* wrong. On the other hand, there are the actual papers and academic journals in which many of these models are first presented. These *do* contain the nitty-gritty details that you need to actually implement a model - up to a point. Reconstructing the full details of how the model's architecure works can often require combing through the paper's appendices, looking through many of the other papers it cites, reading extraneous resources online, etc... - and even with all of this, many important details are often left out. In addition, these resources are all extremely technical, and can be quite difficult to follow until you have spent a considerable amount of time in the academic environment of deep learning. Therefore, a student of machine learning is left with two choices: read Machine Learning 101 blog posts that provide no technical details and often contain mistakes, or read the original papers in their full technical presentation, and try to tease out the actual important implementation details from there. Neither of these options are particularly helpful.

This project is my personal attempt to remedy some of these problems, and create the resource that I wish I had when I was first learning. The goal will be to create a true practical resource for students familiar with the basics, but who might lack some of the technical knowledge or word-of-mouth heuristics needed to really make deep learning work for them. 
